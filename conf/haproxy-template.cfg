# Global settings
global
    pidfile /opt/haproxy/run/haproxy.pid
    user haproxy
    group haproxy
    # turn on stats unix socket
    stats socket /opt/haproxy/run/haproxy.sock level admin expose-fd listeners

    #### Max Connection ####
    # If this value is not set, it will automatically be calculated based on the current file
    # descriptors limit reported by the "ulimit -n" command, possibly reduced to a lower value if a memory limit is enforced,
    # based on the buffer size, memory allocated to compression, SSL cache size, and use or not of SSL and the associated maxsslconn (which can also be automatic).
    maxconn 400000

    ### CPU Pinning ####
    # https://www.haproxy.com/blog/multithreading-in-haproxy/
    # Multi-thread mode
    nbthread 2

    # Multi-process mode
    cpu-map auto:1/1-2 1-2

    # Forces the CPU frequency governor to 'performance' mode.
    # This prevents the processor from entering low-power states (C-states) or downclocking,
    # ensuring the CPU operates at maximum frequency at all times.
    # Critical for high-throughput environments to eliminate "wake-up latency" and minimize response time jitter.
    cpu-policy performance

    #### Tuning ####
    # Status
    stats timeout 2m

    # Buffer Size
    # HAProxy Layer 4 Tuning for High Concurrency (400k Connections) under Memory Constraints (4GiB)
    # Maximize the number of connections accepted per event loop iteration.
    # Setting this to 400,000 ensures the process can rapidly absorb massive connection spikes
    # (e.g., reconnection storms) without backlog accumulation.
    tune.maxaccept 400000
    
    # Reserve buffer space for header rewriting operations.
    # While less critical for pure L4 TCP proxying, setting this to 1024 bytes explicitly
    # ensures optimal buffer alignment and prevents excessive memory reservation.
    tune.maxrewrite 1024
    
    # [CRITICAL] Defines the buffer size allocated per connection.
    # This is the single most important setting for memory management in high-concurrency scenarios.
    # Calculation:
    #   - Target: 400,000 concurrent connections within ~4GiB RAM.
    #   - Constraint: 4GiB / 400,000 ≈ 10KB per connection.
    #   - Selection: 16KB (16384 bytes) is chosen to align with CPU L1 cache (32KB/2) and
    #     kernel page size (4KB * 4), optimizing for cache hits and memory allocation efficiency.
    #   - Warning: A larger value (e.g., 128KB) would require ~50GiB RAM, leading to OOM kills.
    tune.bufsize 16384
    
    # Optimizes system call efficiency by defining the target read size.
    # By matching this with `tune.bufsize`, we encourage the kernel to fill the entire
    # user-space buffer in a single `read()` call, minimizing context switches and CPU overhead.
    tune.recv_enough 16384
    
    # Controls the kernel pipe buffer size for zero-copy operations (splice).
    # Synchronization with `tune.bufsize` (16KB) is essential to:
    #   1. Prevent data fragmentation across L1 cache lines.
    #   2. Minimize latency jitter by reducing data residency time in the pipe.
    #   3. Avoid memory bloat from default large pipe buffers (e.g., 64KB or 1MB).
    tune.pipesize 16384

    # Enable Zero Copy Forward
    # https://docs.haproxy.org/dev/configuration.html#tune.pt.zero-copy-forwarding
    tune.pt.zero-copy-forwarding on

# Defaults
defaults
    mode tcp
    log global
    option dontlognull
    option log-health-checks
    option redispatch
    option nolinger
    option tcpka
    retries 3
    timeout queue 86400s
    timeout connect 86400s
    timeout client 86400s
    timeout server 86400s

#### HAProxy Status ####
listen stats
    #bind {{ MULTUS_IP }}:1936
    bind *:1936
    mode http
    no log
    stats enable
    stats refresh 1s
    # Health check monitoring uri.
    monitor-uri /healthz

    # Add your custom health check monitoring failure condition here.
    stats hide-version
    stats realm Haproxy\ Statistics
    stats uri /

#### HAProxy Prometheus Exporter ####
frontend prometheus-exporter
    bind :9121
    mode http
    http-request use-service prometheus-exporter if { path /metrics }
    no log

#### Redis Replication Cluster-0 (Master) ####
frontend frontend-redis-master-replication-cluster-0
    #bind {{ MULTUS_IP }}:6379
    bind *:6379 tfo
    default_backend backend-redis-master-replication-cluster-0
    mode tcp

    # Enable Splice
    #option splice-auto
    option splice-request
    option splice-response

    # Disable Logs
    # OpenShift OVN-Kubernetes: ServiceIP CIDR / ClusterIP CIDR / GENEVE CIDR / Load Balancer Gateway VIP(Health Check)
    acl skip_log src 172.30.0.0/16 10.128.0.0/14 100.64.0.0/16 192.168.10.11/32

    # Disable logging if any of the above CIDRs match.
    tcp-request content reject if skip_log

backend backend-redis-master-replication-cluster-0
    # TCP Mode
    mode tcp

    # Enable Splice
    #option splice-auto
    option splice-request
    option splice-response

    # Enable retry mechanism for all retryable errors.
    # This directive ensures that if a connection to a backend server fails
    # due to any common and recoverable reason — such as a timeout, TCP reset,
    # no response, or other transient network/server issues — HAProxy will attempt
    # to retry the request to another backend server (up to the number defined by 'retries').
        
    # Especially useful when using TCP Fast Open (TFO), where data is sent with the initial SYN.
    # If TFO fails or the server doesn't support it (e.g., TFO cookie missing), the initial
    # request could fail silently. This retry mechanism helps recover from such failures
    # without affecting client experience.
        
    # Common retryable errors include:
    # - connection-failure
    # - connection-timeout
    # - empty-response
    # - response-timeout
    # - refused-stream (HTTP/2)
    # - maintenance
    # - HTTP 500/502/503/504 (for HTTP mode)
    retry-on all-retryable-errors

    # LoadBalancing Type
    balance source
    hash-type consistent

    # Options
    option tcp-check
    #tcp-check send "AUTH {{ REDIS_PASSWORD }}"\r\n
    tcp-check send {{ AUTH_HEX }}
    tcp-check send PING\r\n
    tcp-check expect string +PONG
    #tcp-check send info\ replication\r\n
    #tcp-check expect string role:master
    tcp-check send QUIT\r\n
    tcp-check expect string +OK

    # Redis Replication Pods
    server redis-master-replication-pod-00 172.16.1.11:6379 tfo check inter 2s rise 1 fall 2 maxconn 400000
    server redis-master-replication-pod-01 172.16.1.12:6379 tfo check inter 2s rise 1 fall 2 maxconn 400000
    server redis-master-replication-pod-02 172.16.1.13:6379 tfo check inter 2s rise 1 fall 2 maxconn 400000
